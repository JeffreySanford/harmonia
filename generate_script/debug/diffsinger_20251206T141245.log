/usr/local/lib/python3.11/dist-packages/lightning/fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
| Hparams chains:  ['configs/base.yaml', 'configs/acoustic.yaml', 'configs/tts/lj/fs2.yaml', '/opt/DiffSinger/checkpoints/0102_xiaoma_pe/config.yaml']
| Hparams: 
[0;33mK_step[0m: 400, [0;33mK_step_infer[0m: 400, [0;33mT_start[0m: 0.4, [0;33mT_start_infer[0m: 0.4, [0;33maccumulate_grad_batches[0m: 1, 
[0;33maudio_num_mel_bins[0m: 80, [0;33maudio_sample_rate[0m: 24000, [0;33maugmentation_args[0m: {'random_pitch_shifting': {'enabled': False, 'range': [-5.0, 5.0], 'scale': 0.75}, 'fixed_pitch_shifting': {'enabled': False, 'targets': [-5.0, 5.0], 'scale': 0.5}, 'random_time_stretching': {'enabled': False, 'range': [0.5, 2.0], 'scale': 0.75}}, [0;33mbackbone_args[0m: {'num_channels': 1024, 'num_layers': 6, 'kernel_size': 31, 'dropout_rate': 0.0, 'strong_cond': True}, [0;33mbackbone_type[0m: lynxnet, 
[0;33mbase_config[0m: ['configs/tts/lj/fs2.yaml'], [0;33mbinarization_args[0m: {'shuffle': False, 'with_align': True, 'with_f0': True, 'with_f0cwt': True, 'with_spk_embed': True, 'with_txt': True, 'with_wav': False}, [0;33mbinarizer_cls[0m: data_gen.tts.base_binarizer.BaseBinarizer, [0;33mbinary_data_dir[0m: data/binary/xiaoma1022_24k_128hop, [0;33mbreathiness_smooth_width[0m: 0.12, 
[0;33mcheck_val_every_n_epoch[0m: 10, [0;33mclip_grad_norm[0m: 1, [0;33mcwt_add_f0_loss[0m: False, [0;33mcwt_hidden_size[0m: 128, [0;33mcwt_layers[0m: 2, 
[0;33mcwt_loss[0m: l1, [0;33mcwt_std_scale[0m: 0.8, [0;33mdataloader_prefetch_factor[0m: 2, [0;33mdataset_size_key[0m: lengths, [0;33mdatasets[0m: [], 
[0;33mdebug[0m: False, [0;33mdec_ffn_kernel_size[0m: 9, [0;33mdec_layers[0m: 4, [0;33mdecoder_type[0m: fft, [0;33mdict_dir[0m: , 
[0;33mdictionaries[0m: {}, [0;33mdiff_accelerator[0m: ddim, [0;33mdiff_speedup[0m: 10, [0;33mdiffusion_type[0m: reflow, [0;33mdropout[0m: 0.1, 
[0;33mds_workers[0m: 4, [0;33mdur_enc_hidden_stride_kernel[0m: ['0,2,3', '0,2,3', '0,1,3'], [0;33mdur_loss[0m: mse, [0;33mdur_predictor_kernel[0m: 3, [0;33mdur_predictor_layers[0m: 2, 
[0;33menc_ffn_kernel_size[0m: 9, [0;33menc_layers[0m: 4, [0;33mencoder_K[0m: 8, [0;33mencoder_type[0m: fft, [0;33mendless_ds[0m: True, 
[0;33menergy_smooth_width[0m: 0.12, [0;33mexp_name[0m: 0102_xiaoma_pe, [0;33mextra_phonemes[0m: [], [0;33mf0_max[0m: 1100, [0;33mf0_min[0m: 65, 
[0;33mffn_act[0m: gelu, [0;33mffn_padding[0m: SAME, [0;33mfft_size[0m: 512, [0;33mfinetune_ckpt_path[0m: None, [0;33mfinetune_enabled[0m: False, 
[0;33mfinetune_ignored_params[0m: ['model.fs2.encoder.embed_tokens', 'model.fs2.txt_embed', 'model.fs2.spk_embed'], [0;33mfinetune_strict_shapes[0m: True, [0;33mfmax[0m: 12000, [0;33mfmin[0m: 30, [0;33mfreezing_enabled[0m: False, 
[0;33mfrozen_params[0m: [], [0;33mgen_dir_name[0m: , [0;33mhidden_size[0m: 256, [0;33mhnsep[0m: vr, [0;33mhnsep_ckpt[0m: checkpoints/vr/model.pt, 
[0;33mhop_size[0m: 128, [0;33minfer[0m: False, [0;33mlambda_aux_mel_loss[0m: 0.2, [0;33mlambda_commit[0m: 0.25, [0;33mlambda_energy[0m: 0.1, 
[0;33mlambda_f0[0m: 1.0, [0;33mlambda_ph_dur[0m: 1.0, [0;33mlambda_sent_dur[0m: 1.0, [0;33mlambda_uv[0m: 1.0, [0;33mlambda_word_dur[0m: 1.0, 
[0;33mload_ckpt[0m: , [0;33mlog_interval[0m: 100, [0;33mloud_norm[0m: False, [0;33mlr[0m: 2.0, [0;33mlr_scheduler_args[0m: {'scheduler_cls': 'torch.optim.lr_scheduler.StepLR', 'step_size': 10000, 'gamma': 0.75}, 
[0;33mmain_loss_log_norm[0m: False, [0;33mmain_loss_type[0m: l2, [0;33mmax_batch_frames[0m: 50000, [0;33mmax_batch_size[0m: 64, [0;33mmax_beta[0m: 0.02, 
[0;33mmax_epochs[0m: 1000, [0;33mmax_eval_sentences[0m: 1, [0;33mmax_eval_tokens[0m: 60000, [0;33mmax_frames[0m: 5000, [0;33mmax_input_tokens[0m: 1550, 
[0;33mmax_sentences[0m: 100000, [0;33mmax_tokens[0m: 20000, [0;33mmax_updates[0m: 60000, [0;33mmax_val_batch_frames[0m: 60000, [0;33mmax_val_batch_size[0m: 1, 
[0;33mmel_base[0m: e, [0;33mmel_loss[0m: l1, [0;33mmel_vmax[0m: 1.5, [0;33mmel_vmin[0m: -6, [0;33mmerged_phoneme_groups[0m: [], 
[0;33mmin_level_db[0m: -120, [0;33mnccl_p2p[0m: True, [0;33mnorm_type[0m: gn, [0;33mnum_ckpt_keep[0m: 3, [0;33mnum_heads[0m: 2, 
[0;33mnum_lang[0m: 1, [0;33mnum_sanity_val_steps[0m: 5, [0;33mnum_spk[0m: 1, [0;33mnum_test_samples[0m: 20, [0;33mnum_valid_plots[0m: 10, 
[0;33moptimizer_adam_beta1[0m: 0.9, [0;33moptimizer_adam_beta2[0m: 0.98, [0;33moptimizer_args[0m: {'optimizer_cls': 'torch.optim.AdamW', 'lr': 0.0006, 'beta1': 0.9, 'beta2': 0.98, 'weight_decay': 0}, [0;33mout_wav_norm[0m: False, [0;33mpe[0m: parselmouth, 
[0;33mpe_ckpt[0m: checkpoints/rmvpe/model.pt, [0;33mpermanent_ckpt_interval[0m: 20000, [0;33mpermanent_ckpt_start[0m: 80000, [0;33mpitch_ar[0m: False, [0;33mpitch_enc_hidden_stride_kernel[0m: ['0,2,5', '0,2,5', '0,2,5'], 
[0;33mpitch_extractor_conv_layers[0m: 2, [0;33mpitch_loss[0m: l1, [0;33mpitch_norm[0m: log, [0;33mpitch_type[0m: frame, [0;33mpl_trainer_accelerator[0m: auto, 
[0;33mpl_trainer_devices[0m: auto, [0;33mpl_trainer_num_nodes[0m: 1, [0;33mpl_trainer_precision[0m: 16-mixed, [0;33mpl_trainer_strategy[0m: {'name': 'auto', 'process_group_backend': 'nccl', 'find_unused_parameters': False}, [0;33mpre_align_args[0m: {'allow_no_txt': False, 'denoise': False, 'forced_align': 'mfa', 'txt_processor': 'en', 'use_sox': False, 'use_tone': True}, 
[0;33mpre_align_cls[0m: data_gen.tts.lj.pre_align.LJPreAlign, [0;33mpredictor_dropout[0m: 0.5, [0;33mpredictor_grad[0m: 0.1, [0;33mpredictor_hidden[0m: -1, [0;33mpredictor_kernel[0m: 5, 
[0;33mpredictor_layers[0m: 2, [0;33mprenet_dropout[0m: 0.5, [0;33mprenet_hidden_size[0m: 256, [0;33mpretrain_fs_ckpt[0m: , [0;33mprocessed_data_dir[0m: data/processed/ljspeech, 
[0;33mprofile_infer[0m: False, [0;33mraw_data_dir[0m: data/raw/LJSpeech-1.1, [0;33mref_norm_layer[0m: bn, [0;33mrel_pos[0m: True, [0;33mreset_phone_dict[0m: True, 
[0;33msampler_frame_count_grid[0m: 6, [0;33msampling_algorithm[0m: euler, [0;33msampling_steps[0m: 20, [0;33msave_best[0m: False, [0;33msave_ckpt[0m: True, 
[0;33msave_codes[0m: ['configs', 'modules', 'tasks', 'utils', 'usr'], [0;33msave_f0[0m: False, [0;33msave_gt[0m: False, [0;33mschedule_type[0m: linear, [0;33mseed[0m: 1234, 
[0;33mshallow_diffusion_args[0m: {'train_aux_decoder': True, 'train_diffusion': True, 'val_gt_start': False, 'aux_decoder_arch': 'convnext', 'aux_decoder_args': {'num_channels': 512, 'num_layers': 6, 'kernel_size': 7, 'dropout_rate': 0.1}, 'aux_decoder_grad': 0.1}, [0;33msort_by_len[0m: True, [0;33mspec_max[0m: [0], [0;33mspec_min[0m: [-12], [0;33mstop_token_weight[0m: 5.0, 
[0;33mtask_cls[0m: tasks.tts.pe.PitchExtractionTask, [0;33mtension_smooth_width[0m: 0.12, [0;33mtest_ids[0m: [68, 70, 74, 87, 110, 172, 190, 215, 231, 294, 316, 324, 402, 422, 485, 500, 505, 508, 509, 519], [0;33mtest_input_dir[0m: , [0;33mtest_num[0m: 523, 
[0;33mtest_set_name[0m: test, [0;33mtime_scale_factor[0m: 1000, [0;33mtimesteps[0m: 1000, [0;33mtrain_set_name[0m: train, [0;33muse_breathiness_embed[0m: False, 
[0;33muse_denoise[0m: False, [0;33muse_energy_embed[0m: False, [0;33muse_gt_dur[0m: False, [0;33muse_gt_f0[0m: False, [0;33muse_key_shift_embed[0m: False, 
[0;33muse_lang_id[0m: False, [0;33muse_pitch_embed[0m: True, [0;33muse_pos_embed[0m: True, [0;33muse_rope[0m: True, [0;33muse_shallow_diffusion[0m: True, 
[0;33muse_speed_embed[0m: False, [0;33muse_spk_embed[0m: False, [0;33muse_spk_id[0m: False, [0;33muse_split_spk_id[0m: False, [0;33muse_tension_embed[0m: False, 
[0;33muse_uv[0m: True, [0;33muse_var_enc[0m: False, [0;33muse_voicing_embed[0m: False, [0;33mval_check_interval[0m: 2000, [0;33mval_with_vocoder[0m: True, 
[0;33mvalid_num[0m: 348, [0;33mvalid_set_name[0m: valid, [0;33mvocoder[0m: pwg, [0;33mvocoder_ckpt[0m: hifigan/model_ckpt_steps_280000.ckpt, [0;33mvoicing_smooth_width[0m: 0.12, 
[0;33mwarmup_updates[0m: 2000, [0;33mweight_decay[0m: 0, [0;33mwin_size[0m: 512, [0;33mwork_dir[0m: checkpoints/0102_xiaoma_pe, 
Resolving vocoder candidate path: /opt/DiffSinger/checkpoints/hifigan/model_ckpt_steps_280000.ckpt
Candidate exists: True
Candidate size: 1016324099
Overwrote hparams["vocoder_ckpt"] with absolute path: /opt/DiffSinger/checkpoints/hifigan/model_ckpt_steps_280000.ckpt
Warning: checkpoint category missing; proceeding with old-format checkpoint.
| load 'model' from 'checkpoints/0102_xiaoma_pe/model_ckpt_steps_60000.ckpt'.
| Load HifiGAN: /opt/DiffSinger/checkpoints/hifigan/model_ckpt_steps_280000.ckpt
DiffSinger programmatic inference failed: [Errno 2] No such file or directory: '/opt/DiffSinger/checkpoints/hifigan/config.json'
